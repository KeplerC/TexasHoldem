{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SCORE_FOLD = 0 #if expected score is below one pairs, then fold\n",
    "\n",
    "#import libraries \n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import urllib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       S1  C1  S2  C2  S3  C3  S4  C4  S5  C5  Hand\n",
      "0       1  10   1  11   1  13   1  12   1   1     9\n",
      "1       2  11   2  13   2  10   2  12   2   1     9\n",
      "2       3  12   3  11   3  13   3  10   3   1     9\n",
      "3       4  10   4  11   4   1   4  13   4  12     9\n",
      "4       4   1   4  13   4  12   4  11   4  10     9\n",
      "5       1   2   1   4   1   5   1   3   1   6     8\n",
      "6       1   9   1  12   1  10   1  11   1  13     8\n",
      "7       2   1   2   2   2   3   2   4   2   5     8\n",
      "8       3   5   3   6   3   9   3   7   3   8     8\n",
      "9       4   1   4   4   4   2   4   3   4   5     8\n",
      "10      1   1   2   1   3   9   1   5   2   3     1\n",
      "11      2   6   2   1   4  13   2   4   4   9     0\n",
      "12      1  10   4   6   1   2   1   1   3   8     0\n",
      "13      2  13   2   1   4   4   1   5   2  11     0\n",
      "14      3   8   4  12   3   9   4   2   3   2     1\n",
      "15      1   3   4   7   1   5   2   4   4  13     0\n",
      "16      1   4   1   1   1   3   3   5   3   2     4\n",
      "17      3   8   3  12   2   7   2   6   1   2     0\n",
      "18      4   8   1  11   4   6   3   2   4  12     0\n",
      "19      3   7   2   7   4  11   1  12   3   1     1\n",
      "20      1  13   4   8   2   7   2  10   3  13     1\n",
      "21      2   6   2   8   1  11   1   4   3   7     0\n",
      "22      3  10   2  10   4   5   1   2   3   8     1\n",
      "23      2   1   3  13   4   6   1   9   4   1     1\n",
      "24      2  10   2   8   1   8   3   2   2  13     1\n",
      "25      2  13   1   5   4   5   4   8   3   3     1\n",
      "26      3   1   1   5   2   7   3  13   1   1     1\n",
      "27      1   7   1   5   4   8   1   6   2   6     1\n",
      "28      3   7   3   9   2  12   2   5   4   4     0\n",
      "29      2  10   1   1   1  12   4   6   2   8     0\n",
      "...    ..  ..  ..  ..  ..  ..  ..  ..  ..  ..   ...\n",
      "24980   4   5   4  13   3  10   1  13   3   2     1\n",
      "24981   3   3   1  11   4   2   3   6   3   9     0\n",
      "24982   4   1   2   1   1   3   2   6   3   1     3\n",
      "24983   3   2   3   1   4  10   4   6   1   3     0\n",
      "24984   2   9   3   1   4   5   2   6   3  10     0\n",
      "24985   3  10   1   5   3   3   4   3   4   2     1\n",
      "24986   2   8   2   5   1  11   4   1   1  12     0\n",
      "24987   2  12   3   9   1   4   3   7   4   3     0\n",
      "24988   4   8   1   8   1   4   3   3   4  12     1\n",
      "24989   4  11   3   2   2  13   4   6   4  12     0\n",
      "24990   4  10   2  11   2   9   4   5   1   8     0\n",
      "24991   2  11   2   9   4   9   4   6   2  10     1\n",
      "24992   4   6   4  10   1   1   1   4   1   3     0\n",
      "24993   2   6   2  13   2   5   4   3   2  11     0\n",
      "24994   4   7   1  10   2   6   1  11   3   7     1\n",
      "24995   2  12   1   2   4   8   3   3   4   6     0\n",
      "24996   2  11   1   5   1  10   4  10   2  13     1\n",
      "24997   3   7   3  13   2   4   1  12   3   8     0\n",
      "24998   1   8   4   1   4  12   1  13   1  10     0\n",
      "24999   4  12   3  11   4   4   3  12   2  12     3\n",
      "25000   2   8   2  12   4   3   4   2   4   4     0\n",
      "25001   2  12   3   5   3   8   4   1   4   2     0\n",
      "25002   4  10   2  13   4   5   4   7   1   5     1\n",
      "25003   1  12   2   9   2  12   4   8   1  13     1\n",
      "25004   3   5   3   7   4  11   3  11   3   2     1\n",
      "25005   3   9   2   6   4  11   4  12   2   4     0\n",
      "25006   4   1   4  10   3  13   3   4   1  10     1\n",
      "25007   2   1   2  10   4   4   4   1   4  13     1\n",
      "25008   2  12   4   3   1  10   1  12   4   9     1\n",
      "25009   1   7   3  11   3   3   4   8   3   7     1\n",
      "\n",
      "[25010 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "#read training file from UCI dataset \n",
    "#train_file = tempfile.NamedTemporaryFile()\n",
    "#urllib.request.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/poker/poker-hand-training-true.data\", train_file.name)\n",
    "\n",
    "CSV_COLUMNS = [\"S1\",\"C1\",\"S2\",\"C2\",\"S3\",\"C3\",\"S4\",\"C4\", \"S5\",\"C5\",\"Hand\"]\n",
    "read_df = pd.read_csv(\"./poker-hand-training-true.data\", names=CSV_COLUMNS, skipinitialspace=True)\n",
    "#read_df = pd.read_csv(\"./poker-hand-training.data\", names=CSV_COLUMNS, skipinitialspace=True)\n",
    "print(read_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2), (0, 4), (0, 6), (0, 8), (2, 4), (2, 6), (2, 8), (4, 6), (4, 8), (6, 8)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/lib/python3/dist-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/lib/python3/dist-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/lib/python3/dist-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/lib/python3/dist-packages/ipykernel/__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       S1  C1  S2  C2  Hand  diff_S  diff_C  diff_S_sc  sum_C  prod_C\n",
      "0       1  10   1  11     9       0       1          0     21    11.0\n",
      "1       2  11   2  13     9       0       2          0     24    14.3\n",
      "2       3  12   3  11     9       0       1          0     23    13.2\n",
      "3       4  10   4  11     9       0       1          0     21    11.0\n",
      "4       4   1   4  13     9       0      12          0     14     1.3\n",
      "5       1   2   1   4     8       0       2          0      6     0.8\n",
      "6       1   9   1  12     8       0       3          0     21    10.8\n",
      "7       2   1   2   2     8       0       1          0      3     0.2\n",
      "8       3   5   3   6     8       0       1          0     11     3.0\n",
      "9       4   1   4   4     8       0       3          0      5     0.4\n",
      "10      1   1   2   1     1       1       0          3      2     0.1\n",
      "11      2   6   2   1     0       0       5          0      7     0.6\n",
      "12      1  10   4   6     0       3       4          9     16     6.0\n",
      "13      2  13   2   1     0       0      12          0     14     1.3\n",
      "14      3   8   4  12     1       1       4          3     20     9.6\n",
      "15      1   3   4   7     0       3       4          9     10     2.1\n",
      "16      1   4   1   1     4       0       3          0      5     0.4\n",
      "17      3   8   3  12     0       0       4          0     20     9.6\n",
      "18      4   8   1  11     0       3       3          9     19     8.8\n",
      "19      3   7   2   7     1       1       0          3     14     4.9\n",
      "20      1  13   4   8     1       3       5          9     21    10.4\n",
      "21      2   6   2   8     0       0       2          0     14     4.8\n",
      "22      3  10   2  10     1       1       0          3     20    10.0\n",
      "23      2   1   3  13     1       1      12          3     14     1.3\n",
      "24      2  10   2   8     1       0       2          0     18     8.0\n",
      "25      2  13   1   5     1       1       8          3     18     6.5\n",
      "26      3   1   1   5     1       2       4          6      6     0.5\n",
      "27      1   7   1   5     1       0       2          0     12     3.5\n",
      "28      3   7   3   9     0       0       2          0     16     6.3\n",
      "29      2  10   1   1     0       1       9          3     11     1.0\n",
      "...    ..  ..  ..  ..   ...     ...     ...        ...    ...     ...\n",
      "24980   1  13   3   2     1       2      11          6     15     2.6\n",
      "24981   3   6   3   9     0       0       3          0     15     5.4\n",
      "24982   2   6   3   1     3       1       5          3      7     0.6\n",
      "24983   4   6   1   3     0       3       3          9      9     1.8\n",
      "24984   2   6   3  10     0       1       4          3     16     6.0\n",
      "24985   4   3   4   2     1       0       1          0      5     0.6\n",
      "24986   4   1   1  12     0       3      11          9     13     1.2\n",
      "24987   3   7   4   3     0       1       4          3     10     2.1\n",
      "24988   3   3   4  12     1       1       9          3     15     3.6\n",
      "24989   4   6   4  12     0       0       6          0     18     7.2\n",
      "24990   4   5   1   8     0       3       3          9     13     4.0\n",
      "24991   4   6   2  10     1       2       4          6     16     6.0\n",
      "24992   1   4   1   3     0       0       1          0      7     1.2\n",
      "24993   4   3   2  11     0       2       8          6     14     3.3\n",
      "24994   1  11   3   7     1       2       4          6     18     7.7\n",
      "24995   3   3   4   6     0       1       3          3      9     1.8\n",
      "24996   4  10   2  13     1       2       3          6     23    13.0\n",
      "24997   1  12   3   8     0       2       4          6     20     9.6\n",
      "24998   1  13   1  10     0       0       3          0     23    13.0\n",
      "24999   3  12   2  12     3       1       0          3     24    14.4\n",
      "25000   4   2   4   4     0       0       2          0      6     0.8\n",
      "25001   4   1   4   2     0       0       1          0      3     0.2\n",
      "25002   4   7   1   5     1       3       2          9     12     3.5\n",
      "25003   4   8   1  13     1       3       5          9     21    10.4\n",
      "25004   3  11   3   2     1       0       9          0     13     2.2\n",
      "25005   4  12   2   4     0       2       8          6     16     4.8\n",
      "25006   3   4   1  10     1       2       6          6     14     4.0\n",
      "25007   4   1   4  13     1       0      12          0     14     1.3\n",
      "25008   1  12   4   9     1       3       3          9     21    10.8\n",
      "25009   4   8   3   7     1       1       1          3     15     5.6\n",
      "\n",
      "[250100 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#generate training cases \n",
    "#because we have only two cards available, we generate two combinations with corresponding result \n",
    "\n",
    "import itertools\n",
    "\n",
    "#select two combinations \n",
    "train_list = list(itertools.combinations(range(0,10,2), 2))\n",
    "print(train_list)\n",
    "\n",
    "frames = []\n",
    "for target in train_list:\n",
    "    local_train_list = [target[0], target[0]+1, target[1], target[1]+1, 10] #append the final result to our table \n",
    "    local_data_frame = read_df.iloc[:, local_train_list]\n",
    "    local_data_frame.columns = [\"S1\",\"C1\",\"S2\",\"C2\", \"Hand\"]\n",
    "    local_data_frame['diff_S'] = abs(local_data_frame['S1'] - local_data_frame['S2'])\n",
    "    local_data_frame['diff_C'] = abs(local_data_frame['C1'] - local_data_frame['C2'])\n",
    "    local_data_frame['diff_S_sc'] = abs((local_data_frame['S1'] - local_data_frame['S2'])) * 3\n",
    "    local_data_frame['sum_C'] = local_data_frame['C1'] + local_data_frame['C2']\n",
    "    local_data_frame['prod_C'] = (local_data_frame['C1'] * local_data_frame['C2']) / 10\n",
    "    frames.append(local_data_frame)\n",
    "training_df = pd.concat(frames)\n",
    "print(training_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "5        1\n",
      "6        1\n",
      "7        1\n",
      "8        1\n",
      "9        1\n",
      "10       1\n",
      "11       0\n",
      "12       0\n",
      "13       0\n",
      "14       1\n",
      "15       0\n",
      "16       1\n",
      "17       0\n",
      "18       0\n",
      "19       1\n",
      "20       1\n",
      "21       0\n",
      "22       1\n",
      "23       1\n",
      "24       1\n",
      "25       1\n",
      "26       1\n",
      "27       1\n",
      "28       0\n",
      "29       0\n",
      "        ..\n",
      "24980    1\n",
      "24981    0\n",
      "24982    1\n",
      "24983    0\n",
      "24984    0\n",
      "24985    1\n",
      "24986    0\n",
      "24987    0\n",
      "24988    1\n",
      "24989    0\n",
      "24990    0\n",
      "24991    1\n",
      "24992    0\n",
      "24993    0\n",
      "24994    1\n",
      "24995    0\n",
      "24996    1\n",
      "24997    0\n",
      "24998    0\n",
      "24999    1\n",
      "25000    0\n",
      "25001    0\n",
      "25002    1\n",
      "25003    1\n",
      "25004    1\n",
      "25005    0\n",
      "25006    1\n",
      "25007    1\n",
      "25008    1\n",
      "25009    1\n",
      "Name: Hand, Length: 250100, dtype: int64\n",
      "       S1  C1  S2  C2  diff_S  diff_C  diff_S_sc  sum_C  prod_C\n",
      "0       1  10   1  11       0       1          0     21    11.0\n",
      "1       2  11   2  13       0       2          0     24    14.3\n",
      "2       3  12   3  11       0       1          0     23    13.2\n",
      "3       4  10   4  11       0       1          0     21    11.0\n",
      "4       4   1   4  13       0      12          0     14     1.3\n",
      "5       1   2   1   4       0       2          0      6     0.8\n",
      "6       1   9   1  12       0       3          0     21    10.8\n",
      "7       2   1   2   2       0       1          0      3     0.2\n",
      "8       3   5   3   6       0       1          0     11     3.0\n",
      "9       4   1   4   4       0       3          0      5     0.4\n",
      "10      1   1   2   1       1       0          3      2     0.1\n",
      "11      2   6   2   1       0       5          0      7     0.6\n",
      "12      1  10   4   6       3       4          9     16     6.0\n",
      "13      2  13   2   1       0      12          0     14     1.3\n",
      "14      3   8   4  12       1       4          3     20     9.6\n",
      "15      1   3   4   7       3       4          9     10     2.1\n",
      "16      1   4   1   1       0       3          0      5     0.4\n",
      "17      3   8   3  12       0       4          0     20     9.6\n",
      "18      4   8   1  11       3       3          9     19     8.8\n",
      "19      3   7   2   7       1       0          3     14     4.9\n",
      "20      1  13   4   8       3       5          9     21    10.4\n",
      "21      2   6   2   8       0       2          0     14     4.8\n",
      "22      3  10   2  10       1       0          3     20    10.0\n",
      "23      2   1   3  13       1      12          3     14     1.3\n",
      "24      2  10   2   8       0       2          0     18     8.0\n",
      "25      2  13   1   5       1       8          3     18     6.5\n",
      "26      3   1   1   5       2       4          6      6     0.5\n",
      "27      1   7   1   5       0       2          0     12     3.5\n",
      "28      3   7   3   9       0       2          0     16     6.3\n",
      "29      2  10   1   1       1       9          3     11     1.0\n",
      "...    ..  ..  ..  ..     ...     ...        ...    ...     ...\n",
      "24980   1  13   3   2       2      11          6     15     2.6\n",
      "24981   3   6   3   9       0       3          0     15     5.4\n",
      "24982   2   6   3   1       1       5          3      7     0.6\n",
      "24983   4   6   1   3       3       3          9      9     1.8\n",
      "24984   2   6   3  10       1       4          3     16     6.0\n",
      "24985   4   3   4   2       0       1          0      5     0.6\n",
      "24986   4   1   1  12       3      11          9     13     1.2\n",
      "24987   3   7   4   3       1       4          3     10     2.1\n",
      "24988   3   3   4  12       1       9          3     15     3.6\n",
      "24989   4   6   4  12       0       6          0     18     7.2\n",
      "24990   4   5   1   8       3       3          9     13     4.0\n",
      "24991   4   6   2  10       2       4          6     16     6.0\n",
      "24992   1   4   1   3       0       1          0      7     1.2\n",
      "24993   4   3   2  11       2       8          6     14     3.3\n",
      "24994   1  11   3   7       2       4          6     18     7.7\n",
      "24995   3   3   4   6       1       3          3      9     1.8\n",
      "24996   4  10   2  13       2       3          6     23    13.0\n",
      "24997   1  12   3   8       2       4          6     20     9.6\n",
      "24998   1  13   1  10       0       3          0     23    13.0\n",
      "24999   3  12   2  12       1       0          3     24    14.4\n",
      "25000   4   2   4   4       0       2          0      6     0.8\n",
      "25001   4   1   4   2       0       1          0      3     0.2\n",
      "25002   4   7   1   5       3       2          9     12     3.5\n",
      "25003   4   8   1  13       3       5          9     21    10.4\n",
      "25004   3  11   3   2       0       9          0     13     2.2\n",
      "25005   4  12   2   4       2       8          6     16     4.8\n",
      "25006   3   4   1  10       2       6          6     14     4.0\n",
      "25007   4   1   4  13       0      12          0     14     1.3\n",
      "25008   1  12   4   9       3       3          9     21    10.8\n",
      "25009   4   8   3   7       1       1          3     15     5.6\n",
      "\n",
      "[250100 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#generate label\n",
    "#do this based on SCORE-FOlD: how expected hand you will fold\n",
    "train_labels = (training_df[\"Hand\"].apply(lambda x: x > SCORE_FOLD)).astype(int)\n",
    "training_df = training_df.drop('Hand', 1)\n",
    "print(train_labels)\n",
    "print(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#do a counting on each cell\n",
    "hand = np.zeros([13, 13])\n",
    "suit = np.zeros([4, 4])\n",
    "l = list(train_labels)\n",
    "for i in range(len(l)):\n",
    "    if(l[i] == 1):\n",
    "        C1 = int(training_df.iloc[i][1])-1\n",
    "        C2 = int(training_df.iloc[i][3])-1\n",
    "        S1 = int(training_df.iloc[i][0])-1\n",
    "        S2 = int(training_df.iloc[i][2])-1\n",
    "        hand[C1][C2] += 1\n",
    "        suit[S1][S2] += 1\n",
    "        \n",
    "print(hand)\n",
    "print(suit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffac4986a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#graph of hand\n",
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(hand, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFAKAgkIAUFAIAIr/A1EOtOSTQMu+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffac4912dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#normalize it with a cap 900, because pair is so obvious \n",
    "for i in range(13):\n",
    "    for j in range(13):\n",
    "        if(hand[i][j] > 900):\n",
    "            hand[i][j] = 900\n",
    "plt.matshow(hand, cmap=plt.cm.gray)\n",
    "\n",
    "#and graph of suit\n",
    "plt.matshow(suit, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250100, 9)\n",
      "(250100, 9)\n",
      "(250100,)\n"
     ]
    }
   ],
   "source": [
    "#then do tensorflow and find parameters \n",
    "\n",
    "print(training_df.shape)\n",
    "trainX = training_df.iloc[:, 0:9].values\n",
    "trainY = train_labels.values\n",
    "\n",
    "learning_rate = 0.01\n",
    "training_epochs = 1000\n",
    "batch_size = 100\n",
    "display_step = 50\n",
    "m, n = trainX.shape\n",
    "#m: number of training samples \n",
    "#n: number of features\n",
    "\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "\n",
    "\n",
    "def fetch_batch(X_train, Y_train, batch_index, batch_size):\n",
    "    X_batch = X_train[batch_index*batch_size: (batch_index+1)*batch_size, :]\n",
    "    y_batch = Y_train[batch_index*batch_size: (batch_index+1)*batch_size]\n",
    "    return X_batch, y_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tensorflow\n",
    "#do logistic regression \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys \n",
    "\n",
    "#enable GPU acceleration\n",
    "\n",
    "device_name = sys.argv[1]  # Choose device from cmd line. Options: gpu or cpu\n",
    "#shape = (int(sys.argv[2]), int(sys.argv[2]))\n",
    "if device_name == \"gpu\":\n",
    "    device_name = \"/gpu:0\"\n",
    "else:\n",
    "    device_name = \"/cpu:0\"\n",
    "\n",
    "    \n",
    "with tf.device(device_name):\n",
    "\n",
    "    #graph input\n",
    "    x = tf.placeholder(tf.float32, [None, n])\n",
    "    Y = tf.placeholder(tf.float32)\n",
    "\n",
    "    #weights \n",
    "    #W = tf.Variable(tf.zeros([n, 1]), name=\"weight\")\n",
    "    W = tf.random_uniform([n, 1], -1.0, 1.0)\n",
    "    b = tf.Variable(np.random.randn(), name=\"bias\")\n",
    "\n",
    "    #model\n",
    "    pred = tf.nn.sigmoid(tf.matmul(x, W) + b)\n",
    "\n",
    "    #cost \n",
    "    cost = tf.reduce_sum(tf.pow(pred-Y, 2))\n",
    "\n",
    "    #optimizer is Gradient Descent\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "    #saver\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "#training\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        average_cost = 0\n",
    "        total_batch = int(m / batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = fetch_batch(trainX, trainY, i, batch_size)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x, Y: batch_y})\n",
    "            average_cost += c/total_batch\n",
    "            #print(W.eval())\n",
    "        \n",
    "        if(epoch+1) % display_step == 0:\n",
    "            print(\"Epoch:\", '%05d' % (epoch+1), \"cost=\", \"{:.20f}\".format(average_cost))\n",
    "            print(\"Now the weight is :\" + str(W.eval()) + \"\\n\")\n",
    "            print(\"Now the weight is :\" + str(b.eval()) + \"\\n\")\n",
    "            save_path = saver.save(sess, \"./model.ckpt\")\n",
    "            \n",
    "    print(\"Optimization Finished!\")\n",
    "    \n",
    "    #model evaluation\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(\"Accuracy:\", accuracy.eval({x: trainX, Y: trainY}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#evaluation \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
